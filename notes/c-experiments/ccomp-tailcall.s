# File generated by CompCert 3.7
# Command line: -S -O2 tailcall.c
	.text
	.align	4
	.globl _g4
_g4:
	.cfi_startproc
	subq	$8, %rsp
	.cfi_adjust_cfa_offset	8
	leaq	16(%rsp), %rax
	movq	%rax, 0(%rsp)
	leaq	0(%rsi,%rdi,1), %rax
	movq	%rsi, %rdi
	movq	%rax, %rsi
	addq	$8, %rsp
	jmp	_f4
	.cfi_endproc
	.text
	.align	4
	.globl _g3
_g3:
	.cfi_startproc
	subq	$8, %rsp
	.cfi_adjust_cfa_offset	8
	leaq	16(%rsp), %rax
	movq	%rax, 0(%rsp)
	movq	%rdi, %rax
	movq	%rsi, %rdi
	leaq	0(%rdi,%rax,1), %rsi
	xorq	%rcx, %rcx
	addq	$8, %rsp
	jmp	_f4
	.cfi_endproc
	.text
	.align	4
	.globl _g6
_g6:
	.cfi_startproc
	subq	$8, %rsp
	.cfi_adjust_cfa_offset	8
	leaq	16(%rsp), %rax
	movq	%rax, 0(%rsp)
	leaq	0(%rsi,%rdi,1), %rax
	movq	%rsi, %rdi
	movq	%rax, %rsi
	addq	$8, %rsp
	jmp	_f4
	.cfi_endproc
	.text
	.align	4
	.globl _h3
_h3:
	.cfi_startproc
	subq	$88, %rsp
	.cfi_adjust_cfa_offset	88
	leaq	96(%rsp), %rax
	movq	%rax, 80(%rsp)
	movq	%rdi, 72(%rsp)
	movq	%rdx, 64(%rsp)
	movq	%rsi, 56(%rsp)
	movq	%rdi, 48(%rsp)
	movq	%rdx, 40(%rsp)
	movq	%rsi, 32(%rsp)
	movq	%rdi, 24(%rsp)
	movq	%rdx, 16(%rsp)
	movq	%rsi, 8(%rsp)
	movq	%rdi, 0(%rsp)
	movq	%rdx, %r9
	movq	%rsi, %r8
	movq	%rdi, %rcx
	call	_f16
	addq	$88, %rsp
	ret
	.cfi_endproc
	.text
	.align	4
	.globl _h16
_h16:
	.cfi_startproc
	subq	$152, %rsp
	.cfi_adjust_cfa_offset	152
	leaq	160(%rsp), %rax
	movq	%rax, 80(%rsp)
	movq	%rbx, 88(%rsp)
	movq	%rbp, 96(%rsp)
	movq	%r12, 104(%rsp)
	movq	%r13, 112(%rsp)
	movq	%r14, 120(%rsp)
	movq	%r15, 128(%rsp)
	movq	72(%rax), %r13
	movq	64(%rax), %r12
	movq	56(%rax), %rax
	movq	%rax, 144(%rsp)
	movq	80(%rsp), %rax
	movq	48(%rax), %rbp
	movq	40(%rax), %rbx
	movq	32(%rax), %r11
	movq	24(%rax), %r10
	movq	%r8, %r15
	movq	80(%rsp), %rax
	movq	16(%rax), %r8
	movq	8(%rax), %r14
	movq	%rdi, 136(%rsp)
	movq	0(%rax), %rdi
	movq	%r12, 72(%rsp)
	movq	%r13, 64(%rsp)
	movq	144(%rsp), %rax
	movq	%rax, 56(%rsp)
	movq	%rbp, 48(%rsp)
	movq	%rbx, 40(%rsp)
	movq	%r11, 32(%rsp)
	movq	%r10, 24(%rsp)
	movq	%r8, 16(%rsp)
	movq	%r14, 8(%rsp)
	movq	%rdi, 0(%rsp)
	movq	%r15, %r8
	movq	%rdx, %rax
	movq	%rcx, %rdx
	movq	%rax, %rcx
	movq	%rsi, %rdi
	movq	136(%rsp), %rsi
	call	_f16
	movq	88(%rsp), %rbx
	movq	96(%rsp), %rbp
	movq	104(%rsp), %r12
	movq	112(%rsp), %r13
	movq	120(%rsp), %r14
	movq	128(%rsp), %r15
	addq	$152, %rsp
	ret
	.cfi_endproc
	.text
	.align	4
	.globl _j16
_j16:
	.cfi_startproc
	subq	$56, %rsp
	.cfi_adjust_cfa_offset	56
	leaq	64(%rsp), %rax
	movq	%rax, 0(%rsp)
	movq	%rbx, 8(%rsp)
	movq	%rbp, 16(%rsp)
	movq	%r12, 24(%rsp)
	movq	%r13, 32(%rsp)
	movq	%r14, 40(%rsp)
	movq	%rcx, %r14
	movq	0(%rsp), %rax
	movq	48(%rax), %rcx
	movq	40(%rax), %r12
	movq	32(%rax), %rbp
	movq	24(%rax), %rbx
	movq	16(%rax), %r11
	movq	8(%rax), %r13
	movq	0(%rax), %r10
	leaq	0(%rdi,%rsi,1), %rax
	leaq	0(%rax,%rdx,1), %rax
	leaq	0(%rax,%r14,1), %rdi
	leaq	0(%r8,%r9,1), %rax
	leaq	0(%rax,%r10,1), %rsi
	leaq	0(%rsi,%r13,1), %rsi
	leaq	0(%r11,%rbx,1), %r9
	leaq	0(%r9,%rbp,1), %r8
	leaq	0(%r8,%r12,1), %rdx
	movq	8(%rsp), %rbx
	movq	16(%rsp), %rbp
	movq	24(%rsp), %r12
	movq	32(%rsp), %r13
	movq	40(%rsp), %r14
	addq	$56, %rsp
	jmp	_f4
	.cfi_endproc
